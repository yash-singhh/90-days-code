{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(\"lets make interview bot\")"
      ],
      "metadata": {
        "id": "iB0x_oRijO4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7by9ymFUPaIS"
      },
      "outputs": [],
      "source": [
        "!pip install -q loguru openai gradio >/dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core imports for OpenAI API interaction and UI\n",
        "import openai\n",
        "import os\n",
        "from loguru import logger #For logging\n",
        "from google.colab import userdata #for handing API Keys\n",
        "import gradio as gr #for UI"
      ],
      "metadata": {
        "id": "WYckP-qQGfr-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "logger.info(f\"OpenAI API key: {'LOADED ✓' if api_key.startswith('sk-') else 'NOT FOUND ✗'}\")"
      ],
      "metadata": {
        "id": "8tpUHf_-GhWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "client = openai.OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oKv56V12GhTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
        "    \"\"\"\n",
        "    Get completion from OpenAI API.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text to send to OpenAI\n",
        "        model (str): OpenAI model to use, defaults to GPT-4\n",
        "\n",
        "    Returns:\n",
        "        str: Generated completion text\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.2\n",
        "    )\n",
        "    final_response = response.choices[0].message.content\n",
        "    logger.info(f\"Mode response: {final_response}\")\n",
        "\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "CsyEvOF0id9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(your_role, candidate_role, your_review):\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    I’m {your_role}. You’re an expert at writing performance reviews. On my behalf, help answer the question for performance reviews below.\n",
        "\n",
        "    {delimiter} Instructions {delimiter}:\n",
        "    - Use the context below to understand my perspective of working with him\n",
        "    - Keep the role of person I’m review {candidate_role} in mind when writing the review\n",
        "    - Use simple language and keep it to the point\n",
        "    - Strictly answer the question mentioned in “question for performance”\n",
        "\n",
        "    {your_review}\n",
        "\n",
        "    - Describe example(s) of the topics selected. What was the context? What actions did they take?\n",
        "    - In your opinion, what impact did their actions have?\n",
        "    - What recommendations do you have for their growth and development? Your feedback can be about any area of their work.\n",
        "\n",
        "\n",
        "    {delimiter} Output in markdown format in following structure:{delimiter}\n",
        "    - Q1: Describe example(s) of the topics selected. What was the context? What actions did they take?\n",
        "    Your answer\n",
        "    - Q2: In your opinion, what impact did their actions have?\n",
        "    Your answer\n",
        "    - Q3: What recommendations do you have for their growth and development? Your feedback can be about any area of their work.\n",
        "    Your answer\n",
        "\n",
        "    Answer: \"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "z0Q3_m2tidrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_review(your_role, candidate_role, your_review):\n",
        "    \"\"\"\n",
        "    Generate a structured performance review using OpenAI.\n",
        "\n",
        "    Args:\n",
        "        your_role (str): Reviewer's role\n",
        "        candidate_role (str): Candidate's role\n",
        "        your_review (str): Initial review text\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted performance review\n",
        "    \"\"\"\n",
        "    prompt = generate_prompt(your_role, candidate_role, your_review)\n",
        "    response = get_completion(prompt)\n",
        "    return response"
      ],
      "metadata": {
        "id": "ZD6Hyj-_idcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    gr.Markdown(\"============================================================\")\n",
        "    gr.Markdown(\"Write performance review in a minute\")  # Title\n",
        "    gr.Markdown(\"============================================================\")\n",
        "\n",
        "    # Input Fields\n",
        "    your_role = gr.Textbox(\n",
        "        label='your role',  # e.g., \"Senior Manager\", \"Team Lead\"\n",
        "    )\n",
        "\n",
        "    candidate_role = gr.Textbox(\n",
        "        label='candidate role',  # e.g., \"Software Engineer\", \"Product Manager\"\n",
        "    )\n",
        "\n",
        "    your_review = gr.Textbox(\n",
        "        label='Briefly descrive your experience of working with candididate...',\n",
        "        # This is the main input where reviewer provides detailed feedback\n",
        "        # Can include:\n",
        "        # - Project details\n",
        "        # - Responsibilities\n",
        "        # - Achievements\n",
        "        # - Behavioral observations\n",
        "    )\n",
        "\n",
        "    # Action button to trigger review generation\n",
        "    write_review = gr.Button(\"Write Review\")\n",
        "\n",
        "    # Output area where the AI-generated review will appear\n",
        "    answer = gr.Markdown(\n",
        "        label='Review'  # Will display formatted review in markdown\n",
        "    )\n",
        "\n",
        "\n",
        "    write_review.click(\n",
        "        fn=generate_review,            # Function to call\n",
        "        inputs=[\n",
        "            your_role,\n",
        "            candidate_role,\n",
        "            your_review\n",
        "        ],\n",
        "        outputs=answer\n",
        "    )\n",
        "\n",
        "\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=True\n",
        ")"
      ],
      "metadata": {
        "id": "zw0Kh3fBinas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sM1oNE6IinVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    user_input = user_input.lower()\n",
        "    if 'hello' in user_input or 'hi' in user_input:\n",
        "        return \"Hello! How can I help you today?\"\n",
        "    elif 'how are you' in user_input:\n",
        "        return \"I'm a bot, so I'm always good! How about you?\"\n",
        "    elif 'bye' in user_input:\n",
        "        return \"Goodbye! Have a great day!\"\n",
        "    else:\n",
        "        return \"Sorry, I don't understand that. Can you ask something else?\"\n",
        "\n",
        "# Example interaction\n",
        "print(chatbot_response('Hello'))\n",
        "print(chatbot_response('How are you?'))\n",
        "print(chatbot_response('Bye'))\n",
        "print(chatbot_response('What is your name?'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3IxmqeKGhQp",
        "outputId": "dec84d12-a3df-4e6e-851c-4560d6f44a9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n",
            "I'm a bot, so I'm always good! How about you?\n",
            "Goodbye! Have a great day!\n",
            "Sorry, I don't understand that. Can you ask something else?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZp6a1zIi9h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"API\"  # Replace with your actual OpenAI API key\n",
        "\n",
        "def chat_with_openai(user_input):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # You can use \"gpt-4o\" or another available model if preferred\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Example usage\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "    reply = chat_with_openai(user_input)\n",
        "    print(\"Chatbot:\", reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "NE82Ao8BGhNt",
        "outputId": "e6ed24fd-4a0b-4e19-9c6b-2d46b4195621"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hey\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-958410029.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot: Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_with_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-8-958410029.py\u001b[0m in \u001b[0;36mchat_with_openai\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_with_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# You can use \"gpt-4o\" or another available model if preferred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJABwnBbHvNv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}